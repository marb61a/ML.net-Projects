Notes from Rubikscode ML.net course
    - https://rubikscode.net/courses/ml-net-full-stack-machine-learning-for-net-developers/
    - Machine Learning for .Net developers
    - https://docs.microsoft.com/en-us/dotnet/machine-learning/
    - https://github.com/dotnet/machinelearning

I am very interested in ML.net as .net is used in RPA tools which gives some benefits
    - Learning C# based machine learning which can be used not only in RPA tools
    - https://docs.uipath.com/ai-fabric/v0/docs/building-ml-packages

There are some pre-requisites for the course
    - VSCode and Visual Studio 2022
        - .net 6 comes with the IDE installation
    - .net Interactive VSCode extension
    - The notebooks involved are similar to Jupyter notebooks
    - C# will be used instead of Python but will be used in an almost script-like manner

There are some datasets that will be used within the course
    - Palmer Penguins Dataset, Boston Housing Dataset, Netflix Prize Dataset, IMDb Sentiment Dataset and Cats vs Dogs

History of Machine Learning
    - https://www.techtarget.com/whatis/A-Timeline-of-Machine-Learning-History
    - https://www.dataversity.net/a-brief-history-of-machine-learning/
    - Machine Learning is no longer an obscure topic
    - Data volumes have increased by orders of magnitude in the last few years
        - By 2025 expected to be around 200 Zettabytes
        - A zettabyte is 1,000,000,000,000,000,000,000 or 10 to the power of 21
    - Machine Learning and Deep Learning are very in demand skills
    - A quick definition of Machine Learning
        - Machine Learning is the branch of computer science which uses statistical techniques to give computers the ability to learn
    - Learning in this context means gaining the ability to perform tasks to success rates through experience
    - Machine Learning tries to solves problems that are tough to solve by people or standard software
        - Problems include classification, regression, forecasting and anomaly detection

Gradient Descent
    - https://en.wikipedia.org/wiki/Gradient_descent
    - https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html
    - Gradient Descent is the essential optimization technique and one of the main ingredients of some algorithms
        - It is the most popular optimisation technique and the basis for all others

Performance Metrics
    - Evaluation metrics are in general grouped by the task being solved by an algorithm
        - For example binary classification uses a different set of metrics to determine algorithm performance than would be used in regression
    - https://neptune.ai/blog/evaluation-metrics-binary-classification
    - There are some terms to consider when assessing classification model performance
        - Confusion Matrix or Error Matrix
            - https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/
            - Used to describe classification model performance when true values are known
        - Precision is another technique
            - It also carries more information than accuracy
            - It asks the question about what proportion of positive identications were correct
            - The value goes from 0 to 1 and the closer to 1 the better
        - Recall which is described as the ability of the classifier to find all the positive samples
            - This metric tries to answer the question, What proportion of actual positives was identified correctly
            - It is very similar to precision but differs slightly as precision measure result relevance
            - Recall on the other hand measures how many truly relevant results are returned
        - Accuracy is calculated as a number of correct predictions divided by the total number of predictions
            - This can be trick as it may lead to incorrect impressions about the model especiall when using imbalanced dataschool
            - This means thet if the model performs well on the dominant class in the dataset it may not perform as well on others
            - Models that overfit have 100% accuracy
        - F1 Score is probably the most popular metric that combines precision and recall
            - It represents the harmonic mean of both
            - Its formula is (Precision * Recall / Precision + Recall) * 2 
        - Receiver Operating Characteristic (ROC) curve & Area Under the curve (AUC)
            - When an ML algorithm is predicting the class of a sample it calculates the probability that it belongs to a certain class
            - If the value is above a certain threshold then it is label as that class
            - ROC curves show the true positive rate against the false positive rate for certain thresholds 
            - The AUC metric is used as a measure of performance
            - This means that ROC is a probability curve where AUC measures the separability
            - This combination tells the model to  distinguish classes and the higher the value the better
        - Area under Precision-Recall Curve (AUPRC)
        - 
    -
