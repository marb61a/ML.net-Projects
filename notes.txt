Notes from Rubikscode ML.net course
    - https://rubikscode.net/courses/ml-net-full-stack-machine-learning-for-net-developers/
    - Machine Learning for .Net developers
    - https://docs.microsoft.com/en-us/dotnet/machine-learning/
    - https://github.com/dotnet/machinelearning

Complete suite of .NET versions of ML\AI libraries
    - https://scisharp.github.io/SciSharp/
    - https://github.com/SciSharp
    - https://github.com/dotnet/TorchSharp

Nimbus ML provides python bindings for ML.NET
    - https://docs.microsoft.com/en-us/nimbusml/overview
    - https://github.com/microsoft/NimbusML

Using Model Builder in VSCode
    - https://www.youtube.com/watch?v=R8aCkjSTSuc

I am very interested in ML.net as .net is used in RPA tools which gives some benefits
    - Learning C# based machine learning which can be used not only in RPA tools
    - https://docs.uipath.com/ai-fabric/v0/docs/building-ml-packages

There are some pre-requisites for the course
    - VSCode and Visual Studio 2022
        - .net 6 comes with the IDE installation
    - .net Interactive VSCode extension
    - The notebooks involved are similar to Jupyter notebooks
    - C# will be used instead of Python but will be used in an almost script-like manner

There are some datasets that will be used within the course
    - Palmer Penguins Dataset, Boston Housing Dataset, Netflix Prize Dataset, IMDb Sentiment Dataset and Cats vs Dogs

History of Machine Learning
    - https://www.techtarget.com/whatis/A-Timeline-of-Machine-Learning-History
    - https://www.dataversity.net/a-brief-history-of-machine-learning/
    - Machine Learning is no longer an obscure topic
    - Data volumes have increased by orders of magnitude in the last few years
        - By 2025 expected to be around 200 Zettabytes
        - A zettabyte is 1,000,000,000,000,000,000,000 or 10 to the power of 21
    - Machine Learning and Deep Learning are very in demand skills
    - A quick definition of Machine Learning
        - Machine Learning is the branch of computer science which uses statistical techniques to give computers the ability to learn
    - Learning in this context means gaining the ability to perform tasks to success rates through experience
    - Machine Learning tries to solves problems that are tough to solve by people or standard software
        - Problems include classification, regression, forecasting and anomaly detection

Gradient Descent
    - https://en.wikipedia.org/wiki/Gradient_descent
    - https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html
    - Gradient Descent is the essential optimization technique and one of the main ingredients of some algorithms
        - It is the most popular optimisation technique and the basis for all others

Performance Metrics
    - Evaluation metrics are in general grouped by the task being solved by an algorithm
        - For example binary classification uses a different set of metrics to determine algorithm performance than would be used in regression
    - https://neptune.ai/blog/evaluation-metrics-binary-classification
    - There are some terms to consider when assessing classification model performance
        - Confusion Matrix or Error Matrix
            - https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/
            - Used to describe classification model performance when true values are known
        - Precision is another technique
            - It also carries more information than accuracy
            - It asks the question about what proportion of positive identications were correct
            - The value goes from 0 to 1 and the closer to 1 the better
        - Recall which is described as the ability of the classifier to find all the positive samples
            - This metric tries to answer the question, What proportion of actual positives was identified correctly
            - It is very similar to precision but differs slightly as precision measure result relevance
            - Recall on the other hand measures how many truly relevant results are returned
        - Accuracy is calculated as a number of correct predictions divided by the total number of predictions
            - This can be trick as it may lead to incorrect impressions about the model especiall when using imbalanced data
            - This means thet if the model performs well on the dominant class in the dataset it may not perform as well on others
            - Models that overfit have 100% accuracy
        - F1 Score is probably the most popular metric that combines precision and recall
            - It represents the harmonic mean of both
            - Its formula is (Precision * Recall / Precision + Recall) * 2 
        - Receiver Operating Characteristic (ROC) curve & Area Under the curve (AUC)
            - When an ML algorithm is predicting the class of a sample it calculates the probability that it belongs to a certain class
            - If the value is above a certain threshold then it is label as that class
            - ROC curves show the true positive rate against the false positive rate for certain thresholds 
            - The AUC metric is used as a measure of performance
            - This means that ROC is a probability curve where AUC measures the separability
            - This combination tells the model to  distinguish classes and the higher the value the better
        - Area under Precision-Recall Curve (AUPRC)
            - In order to correctly evaluate a model, both metrics need to be taken into consideration
            - Unfortunately as precision improves it usually reduces recall and the opposite is also true
            - The precision-recall curve shows the tradeoff between precision and recall
            - Areas under the curve represents both high recall and high precision
            - High scores for both show that the classifier is returning accurate results with a majority of positive results
    - Multi-Class Classification Metrics
        - Using multi-class classification we can use some of the same metrics that we use for binary classification
        - There are some differences for multi-class classification though
        - Confusion Matric, the difference when being used with multi-class is that each class has a row
        - Micro and Macro Accuracy
            - An accuracy formula can be applied for binary classification for eash class in a dataset
            - There are 2 different ways, the first is when all classes are treated equally, the metric is computed independently for each class and the average is taken
            - This first method is called Macro accuracy, the second is called Micro Accuracy
            - This is when we aggregate the contributions of all classes to compute the average metric
            - Micro Accuracy is a more reliable metric as it tries to account for any class imbalance
        - Log-Loss & Log-Loss Reduction
            - This is one of the most commonly used metrics in kaggle competitions
            - Log Loss is a metric that quantifies the accuracy of a classifier by penalizing false classifications
            - This metric’s value represents the amount of uncertainty of our prediction based on how much it varies from the actual label
            - Log-Loss Reduction is also called reduction in information gain – RIG
            - It gives a measure of how much a model improves on a model that gives random predictions
            - The close that RIG is to 1 the better the model
    - Regression Metrics 
        - Goals from regression problems differ to classification problems so different metrics are needed
        - Regression output is always continuous and the metrics need to match this
        - Mean Absolute Error – MAE
            - This calculates the average absolute distance (error) between predicted and targeted values
            - The closer to 0 the better, this also deals with outliers fairly well
        - Mean Squared Error – MSE
            - This is probably the most popular metric of all regression metrics
            - This calculates the average squared distance (error) between predicted and targeted values
            - Results are non-negative values and the goal is to get this value as close to zero as possible
            - This function is often used as a loss function of a machine learning model
        - Root Mean Squared Error – RMSE
            - This is a variation of the MSE metric
            - It shows what is the average deviation in predictions from the actual values
            - It makes and assumption that errors are unbiased and follows normal distribution 
            - RMSE is also a non-negative value and ) is the ideal value to be achieved
            - Lower RMSE values are better than higher
            - Outliers do affect this metric so a dataset must have them removed prior to using this metric
        - R Squared
            - R Squared is used when a more intuitive approach than MSE or RMSE is needed
            - It is also known as the coefficient of determination and is very popular
            - https://en.wikipedia.org/wiki/Coefficient_of_determination

How does ML.NET fit
    - ML.NET is Microsoft's ML framework which allows for model running, training etc within the .net ecosystem
    - ML.NET is faster that Pytorch using CPU
    - ML.NET was designed to be intuitive for .NET developers
    - The DataView class borrows from database concepts and is the reason why ML.NET is fast
    - ML.NEt performance on the GPU is not as good as Pytorch
    - Data Preprocession can be complicated
    - There not that many tools for data visualisation
    
Intuition to Linear Regression
    - https://machinelearningmastery.com/linear-regression-for-machine-learning/
    - The output of solving a regression problem is a continuous numerical value
        - One of the most famous is predicting the price of a house based on tenants ages which are independent variables
    - There are multiple sources for learning about the mathematics involved in linear regression
        - https://www.analyticsvidhya.com/blog/2021/08/understanding-linear-regression-with-mathematical-insights/
    - Multiple linear regression uses the reknowned Boston housing dataset
        - https://corporatefinanceinstitute.com/resources/knowledge/other/multiple-linear-regression/

Using Notebooks for Linear Regression
    - There are several steps needed
    - Install packages (NNuGet) and add using directives
    - Load and split the data
    - Train the model
    - Evaluate the model
    - Save the model
    - Load and predict

ML.NET Linear Regression
    - Online Gradient Descent
        - This is a variation of Stochastic Gradient Descent
        - It has a choice of loss functions and an option to update the weight vector which uses the vector average seen over time
    - SDCA which stands for Stochastic Dual Coordinate Ascent
        - It is another variation on Stochastic  Gradient Descent
        - This is suitable for large datasets as it can be scaled easily

Using C# Notebooks in VSCode
    - Files will still have the .ipynb extension
    - The kernel that will be used though is .NET interactive rather than a Python kernel
    - When installing packages use #r and then package name
        - In python notebooks this is done with an !
    - When loading a csv file
        - Use LoadFromTextFile<> which is part of MLContext.Data
        - This takes a couple of parameters, the name of the class (type) between the <>
        - The file path and whether the file has headers in the following brackets
            - Using the hasHeader directive which is set to true or false
        - Then the file delimiter is added using the separatorChar directive followed in this case by a comma
    - Splitting a dataset into testing and training
        - Again use MLContext.Data this time adding the TrainTestSplit method
        - The first parameter is the dataview created when loading the data
        - The second parameter is the amount of data to be used for testing using the testFraction directive which is set to 0.2 which equals 20%
        - The training dataset can be examined by using the variable that is assigned to the split and adding the TrainSet method for the training data
        - Then chain the ToTabularDataResource method on
        !!!! - Using a semi-colon will prevent the table from displaying
        - The test portion of the dataset can be loaded similar to above but using the TestSet method
    - Training the model
        - This uses the MLContext followed by Regression which then has trainers and finally the algorithm which is being used
        - In this case it is the SDCA algorithm being used to train the data
        - This takes 2 parameters which are label column name and feature
            - A feature column is added using the featureColumnName which is then given a value
            - A label column is defined using the labelColumnName directive which is then given a value
    -

Troubleshooting
Running C# code from CLI in VSCode
    - https://docs.microsoft.com/en-us/dotnet/core/tutorials/with-visual-studio-code?pivots=dotnet-6-0
    - https://www.youtube.com/watch?v=CO4BGZOuUkM&t=435s

Install ML.NET into a project
    - https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/install-ml-net-cli?tabs=windows
    - dotnet tool install --global mlnet-win-x64
    - Confirm installation has worked by the following command
        - mlnet

Install MathNet package into project
    - https://www.nuget.org/packages/MathNet.Numerics/
    - Using the .NET_CLI -- dotnet add package Mathnet.Numerics
    - Versions can be specified but if a version is not specified then the latest is installed
